{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362fd083-292e-4e99-816c-8933e8b51a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries and data files\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import keras\n",
    "import keras_nlp\n",
    "from keras import layers\n",
    "#from keras import ops\n",
    "from keras.layers import TextVectorization\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.python.keras import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b88d13-c701-49ff-b9d9-1e11aa967260",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_non_seizure_data = np.load('./eeg_data_non_pre_seizure.npy')\n",
    "eeg_pre_seizure_data = np.load('./eeg_data_pre_seizure_chl60_pad_60.npy')\n",
    "eeg_pre_seizure_data_zero_padding = np.load('./eeg_data_pre_seizure_chl60_pad_0.npy')\n",
    "signal_labels = ['EEG Fp1-REF', 'EEG Fp2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', 'EEG Fz-REF', 'EEG Cz-REF', 'EEG Pz-REF', 'ECG EKG-REF', 'Resp Effort-REF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec94847-a980-437f-b6f2-6de0afd309fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualize_eeg_channels(signal,offset=0.0005):\n",
    "    # Set the number of channels and the offset between each channel\n",
    "    np.random.seed(42)\n",
    "    n_channels = len(signal)\n",
    "    offset = 0.0005\n",
    "    \n",
    "    # Set the left and right margins for the window in which we want to plot the data at\n",
    "    \n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    # Plot each signal with an offset\n",
    "    for i in range(n_channels-2): # Remove the EKG and Effor\n",
    "      ax.plot(signal[i] + i * offset, label=signal_labels[i])\n",
    "    \n",
    "    # Set the y-axis labels to the signal labels\n",
    "    ax.set_yticks(np.arange(n_channels-2) * offset)\n",
    "    ax.set_yticklabels(signal_labels[:-2])\n",
    "    \n",
    "    # Set the x-axis label\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    \n",
    "    # Add a legend\n",
    "    #plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a2cedf9-c6a8-4c2c-87c8-46e35ecaef7d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## vizualize non seizure patterns\n",
    "for i in range(5):\n",
    "    vizualize_eeg_channels(eeg_non_seizure_data[random.randint(0,len(eeg_non_seizure_data))],offset=0.0005)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c79c53b-644a-40a4-9c66-a449992ba6d9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## vizualize pre seizure patterns\n",
    "for i in range(5):\n",
    "    vizualize_eeg_channels(eeg_pre_seizure_data[random.randint(0,len(eeg_pre_seizure_data))],offset=0.0005)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fc66e6c-e3f3-477c-8e46-479fdec3cc32",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## vizualize pre seizure patterns zero-padding\n",
    "for i in range(5):\n",
    "    vizualize_eeg_channels(eeg_pre_seizure_data[random.randint(0,len(eeg_pre_seizure_data_zero_padding)-1)],offset=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37631606-4e68-420a-9681-675db67888f2",
   "metadata": {},
   "source": [
    "# One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5dba7a7-4bcd-477b-ba21-884be427dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "for i in range(len(eeg_pre_seizure_data)):\n",
    "    y.append(np.array([0,1]))\n",
    "#for i in range(len(eeg_non_seizure_data)):\n",
    "for i in range(250):\n",
    "    y.append(np.array([1,0]))\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb51e8f-faed-4616-8122-6e291b9653b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((eeg_pre_seizure_data[:,:19], eeg_non_seizure_data[:250,:19]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc769a5-b66c-4c8a-b941-2f1c1268b50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 19, 15104)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3df675-eab3-4d7c-bcf5-45fb7442752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_wise_stats_patient_channel(patient):\n",
    "    patient_embedding=[]\n",
    "    for channel in range(19):\n",
    "        mean=np.mean(np.array(np.split(X[patient][channel],np.arange(int(X.shape[2]/256))*256)[1:]), axis=1)\n",
    "        std=np.mean(np.array(np.split(X[patient][channel],np.arange(int(X.shape[2]/256))*256)[1:]), axis=1)\n",
    "        min=np.min(np.array(np.split(X[patient][channel],np.arange(int(X.shape[2]/256))*256)[1:]), axis=1)\n",
    "        max=np.max(np.array(np.split(X[patient][channel],np.arange(int(X.shape[2]/256))*256)[1:]), axis=1)\n",
    "        median=np.median(np.array(np.split(X[patient][channel],np.arange(int(X.shape[2]/256))*256)[1:]), axis=1)\n",
    "        info=np.array([mean,std,min,max,median])\n",
    "        patient_embedding.append(info)\n",
    "    patient_embedding=np.array(patient_embedding)\n",
    "    return np.concatenate(patient_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7726395-fef2-46aa-948a-eea183611a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 482/482 [00:04<00:00, 116.79it/s]\n"
     ]
    }
   ],
   "source": [
    "X_reduced_len=[]\n",
    "for i in tqdm(range(len(X))):\n",
    "    X_reduced_len.append(get_second_wise_stats_patient_channel(i))\n",
    "X=np.array(X_reduced_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f82a25c-3a63-43b5-bbc1-880285f76b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 95, 59)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f5e7ec-7fae-4acc-ad35-ead3a77ef79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([np.array([(X[index][channel]-np.min(X[index][channel]))/(np.max(X[index][channel])-np.min(X[index][channel])+0.000001) for channel in range(X.shape[1])]) for index in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae1a08a4-301b-4e7d-bc47-997b4cb3e7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 95, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f0d0f7-ac00-4442-b692-ff724839a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.moveaxis(X,-1,-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367c12b4-d70f-420c-85e2-a8097267effe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 59, 95)\n",
      "(482, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a14cee0-c393-48db-9cdc-cd0496b826d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9af7dbdf-749e-4d63-89af-3d40fe8fbdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 59, 95) (337, 2)\n",
      "(145, 59, 95) (145, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf727019-6bf3-4d6b-b3b6-eda250468150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras.ops as ops\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:,tf.newaxis, tf.newaxis, :], dtype='int32')\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "                \"dense_dim\": self.dense_dim,\n",
    "                \"num_heads\": self.num_heads,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class Token_and_PositionalEmbedding(layers.Layer):\n",
    "    #def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "    def __init__(self, sequence_length, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "       \n",
    "        #self.position_embeddings = layers.Embedding(\n",
    "        #    input_dim=sequence_length, output_dim=embed_dim\n",
    "        #)\n",
    "\n",
    "        self.position_embeddings = keras_nlp.layers.SinePositionEncoding(\n",
    "           sequence_length, **kwargs\n",
    "        )\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "        #self.vocab_size = vocab_size\n",
    "        #self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "    \n",
    "        positional_encoding = self.position_embeddings(inputs)\n",
    "\n",
    "        return positional_encoding\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if mask is None:\n",
    "            return None\n",
    "        else:\n",
    "            return tf.math.not_equal(inputs,0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"sequence_length\": self.sequence_length,\n",
    "                \"vocab_size\": self.vocab_size,\n",
    "                \"embed_dim\": self.embed_dim,\n",
    "            }\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9fe4b5-8348-41a2-a157-e2d52a5ba504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(target, output, weights):\n",
    "    target = tf.convert_to_tensor(target)\n",
    "    output = tf.convert_to_tensor(output)\n",
    "    weights = tf.convert_to_tensor(weights, dtype=target.dtype)\n",
    "\n",
    "    epsilon_ = tf.constant(tf.keras.backend.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n",
    "\n",
    "    # Compute cross-entropy from probabilities.\n",
    "    bce = weights[1] * target * tf.math.log(output + epsilon_)\n",
    "    bce += weights[0] * (1 - target) * tf.math.log(1 - output + epsilon_)\n",
    "    return -bce\n",
    "\n",
    "class WeightedBinaryCrossentropy:\n",
    "    def __init__(\n",
    "        self,\n",
    "        label_smoothing=0.0,\n",
    "        weights = [1.0, 1.0],\n",
    "        axis=-1,\n",
    "        name=\"weighted_binary_crossentropy\",\n",
    "        fn = None,\n",
    "    ):\n",
    "        \"\"\"Initializes `WeightedBinaryCrossentropy` instance.\n",
    "        Args:\n",
    "          from_logits: Whether to interpret `y_pred` as a tensor of\n",
    "            [logit](https://en.wikipedia.org/wiki/Logit) values. By default, we\n",
    "            assume that `y_pred` contains probabilities (i.e., values in [0,\n",
    "            1]).\n",
    "          label_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When >\n",
    "            0, we compute the loss between the predicted labels and a smoothed\n",
    "            version of the true labels, where the smoothing squeezes the labels\n",
    "            towards 0.5.  Larger values of `label_smoothing` correspond to\n",
    "            heavier smoothing.\n",
    "          axis: The axis along which to compute crossentropy (the features\n",
    "            axis).  Defaults to -1.\n",
    "          name: Name for the op. Defaults to 'weighted_binary_crossentropy'.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weights = weights # tf.convert_to_tensor(weights)\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.name = name\n",
    "        self.fn = weighted_binary_crossentropy if fn is None else fn\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "        self.label_smoothing = tf.convert_to_tensor(self.label_smoothing, dtype=y_pred.dtype)\n",
    "\n",
    "        def _smooth_labels():\n",
    "            return y_true * (1.0 - self.label_smoothing) + 0.5 * self.label_smoothing\n",
    "\n",
    "        y_true = tf.__internal__.smart_cond.smart_cond(self.label_smoothing, _smooth_labels, lambda: y_true)\n",
    "\n",
    "        return tf.reduce_mean(self.fn(y_true, y_pred, self.weights),axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.name, \"weights\": self.weights, \"fn\": self.fn}\n",
    "\n",
    "        # base_config = super().get_config()\n",
    "        return dict(list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        \"\"\"Instantiates a `Loss` from its config (output of `get_config()`).\n",
    "        Args:\n",
    "            config: Output of `get_config()`.\n",
    "        \"\"\"\n",
    "        if saving_lib.saving_v3_enabled():\n",
    "            fn_name = config.pop(\"fn\", None)\n",
    "            if fn_name:\n",
    "                config[\"fn\"] = get(fn_name)\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92b448a-0227-4a89-b44d-8dc3fc2300f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = X.shape[2]\n",
    "latent_dim = 1024\n",
    "num_heads = 6\n",
    "signal_len = X.shape[1]\n",
    "max_hamiltonian_len = 2\n",
    "hamiltonian_cycle = y_train\n",
    "def get_model():\n",
    "    signal = keras.Input(shape=(signal_len,embed_dim), dtype=\"float64\")\n",
    "\n",
    "    pos_emb_1= Token_and_PositionalEmbedding(signal_len)(signal)\n",
    "\n",
    "    signal=tf.keras.layers.Add()([signal, pos_emb_1])\n",
    "\n",
    "    signal_lstm = layers.LSTM(units=256, return_sequences=True, activation=\"tanh\")(signal)\n",
    "\n",
    "    pos_emb_2= Token_and_PositionalEmbedding(signal_len)(signal_lstm)\n",
    "    \n",
    "    signal_pos=tf.keras.layers.Add()([signal_lstm, pos_emb_2])\n",
    "    \n",
    "    x_att= keras.layers.MultiHeadAttention(num_heads,embed_dim)(query=signal_pos,value=signal_pos,key=signal_pos)\n",
    "\n",
    "    x_res1=tf.keras.layers.Add()([x_att, signal_pos])\n",
    "    x_ln1=layers.LayerNormalization()(x_res1)\n",
    "    \n",
    "    x_2 = layers.Dense(latent_dim, activation=\"relu\")(x_ln1)\n",
    "    x_2=layers.Dense(embed_dim)(x_2)\n",
    "\n",
    "    x_res2=tf.keras.layers.Add()([x_att, x_ln1])\n",
    "    x_ln2=layers.LayerNormalization()(x_res2)\n",
    "    \n",
    "    x_3 = keras.layers.Flatten()(x_ln2)\n",
    "    output = keras.layers.Dense(2, activation='sigmoid')(x_3)\n",
    "    model = keras.Model(inputs=signal, outputs=output)\n",
    "    return model\n",
    "\n",
    "transformer_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86768821-0312-47e7-9e93-a187152be36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ef9da05-01ee-4250-a9f6-cd4701fb7b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 59, 95)]     0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 59, 256)      360448      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " token_and__positional_embeddin  (None, 59, 256)     0           ['lstm_1[1][0]']                 \n",
      " g_3 (Token_and_PositionalEmbed                                                                   \n",
      " ding)                                                                                            \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 59, 256)      0           ['lstm_1[1][0]',                 \n",
      "                                                                  'token_and__positional_embedding\n",
      "                                                                 _3[1][0]']                       \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 59, 256)     585646      ['add_5[1][0]',                  \n",
      " eadAttention)                                                    'add_5[1][0]',                  \n",
      "                                                                  'add_5[1][0]']                  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 59, 256)      0           ['multi_head_attention_1[1][0]', \n",
      "                                                                  'add_5[1][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 59, 256)     512         ['add_6[1][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 59, 256)      0           ['multi_head_attention_1[1][0]', \n",
      "                                                                  'layer_normalization_2[1][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 59, 256)     512         ['add_7[1][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 15104)        0           ['layer_normalization_3[1][0]']  \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 2)            30210       ['flatten_1[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 977,328\n",
      "Trainable params: 977,328\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f278c335-3443-4888-bb25-e12c53f74fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "     \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "        val_targ = self.model.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print ( \"— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    " \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0c9911e-0a43-410d-8321-cc435345c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def f1_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6740ca6d-0207-49e8-b6fe-cb5411871766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 4s 78ms/step - loss: 0.8305 - val_loss: 0.7428\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7242 - val_loss: 0.7100\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7091 - val_loss: 0.7046\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6894 - val_loss: 0.6887\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6923 - val_loss: 0.7116\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6846 - val_loss: 0.6804\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6995 - val_loss: 0.6910\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7131 - val_loss: 0.6822\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6881 - val_loss: 0.6716\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6727 - val_loss: 0.7690\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6873 - val_loss: 0.6888\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6619 - val_loss: 0.6523\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6547 - val_loss: 0.6455\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6599 - val_loss: 0.6554\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6340 - val_loss: 0.6215\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6525 - val_loss: 0.7611\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7680 - val_loss: 0.9205\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.7298 - val_loss: 0.7363\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.6529 - val_loss: 0.6516\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6562 - val_loss: 0.6253\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6555 - val_loss: 0.6662\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6306 - val_loss: 0.6139\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5994 - val_loss: 0.6184\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5983 - val_loss: 0.6003\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5834 - val_loss: 0.6494\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5984 - val_loss: 0.6185\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5575 - val_loss: 0.6173\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5584 - val_loss: 0.7176\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.7068 - val_loss: 0.6384\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6568 - val_loss: 0.6297\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6161 - val_loss: 0.6533\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5444 - val_loss: 0.6693\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5686 - val_loss: 0.8292\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5889 - val_loss: 0.6463\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5351 - val_loss: 0.6721\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5288 - val_loss: 0.6767\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5030 - val_loss: 0.6719\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4859 - val_loss: 0.7612\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4807 - val_loss: 0.7068\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4912 - val_loss: 0.7778\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4531 - val_loss: 0.6229\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4239 - val_loss: 0.7388\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5277 - val_loss: 0.7813\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4563 - val_loss: 0.8168\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4446 - val_loss: 0.6290\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3903 - val_loss: 0.8046\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5257 - val_loss: 0.6456\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.4437 - val_loss: 0.6788\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.3842 - val_loss: 0.8374\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3751 - val_loss: 0.7109\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3595 - val_loss: 0.6986\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3708 - val_loss: 0.6446\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3381 - val_loss: 0.7916\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3228 - val_loss: 0.9336\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.3411 - val_loss: 0.6957\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2932 - val_loss: 0.6797\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2445 - val_loss: 0.8063\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2739 - val_loss: 1.2439\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4399 - val_loss: 0.7732\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3213 - val_loss: 0.7618\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2909 - val_loss: 0.6263\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3174 - val_loss: 0.5549\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3385 - val_loss: 0.9387\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3058 - val_loss: 0.7279\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2539 - val_loss: 0.8793\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3211 - val_loss: 0.8602\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2284 - val_loss: 0.8469\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1819 - val_loss: 1.0764\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.3009 - val_loss: 1.1212\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2459 - val_loss: 0.8427\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2052 - val_loss: 1.0167\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1549 - val_loss: 0.8204\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2918 - val_loss: 0.7779\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2548 - val_loss: 0.8090\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1652 - val_loss: 0.8739\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1683 - val_loss: 1.0034\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1916 - val_loss: 0.9620\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1730 - val_loss: 1.0695\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1291 - val_loss: 0.8302\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0841 - val_loss: 0.9306\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0594 - val_loss: 1.2978\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0568 - val_loss: 1.6885\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1850 - val_loss: 1.4765\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1992 - val_loss: 1.1372\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0995 - val_loss: 0.9161\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0645 - val_loss: 1.3331\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0424 - val_loss: 1.2997\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0337 - val_loss: 1.2259\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0233 - val_loss: 1.3099\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1506 - val_loss: 1.7246\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.5181 - val_loss: 0.6666\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.6380 - val_loss: 0.6415\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.4743 - val_loss: 0.5874\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3495 - val_loss: 0.5461\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2853 - val_loss: 0.6161\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1974 - val_loss: 0.5283\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1320 - val_loss: 0.5941\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0937 - val_loss: 0.7332\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0805 - val_loss: 0.9391\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0682 - val_loss: 0.9502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2997c940dc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100 # This should be at least 30 for convergence\n",
    "wbce = WeightedBinaryCrossentropy(weights = [1.0, 1.0])\n",
    "val_data=X_test[:1000]\n",
    "val_target=y_test[:1000]\n",
    "\n",
    "#model.compile(\n",
    "#    keras.optimizers.Adam(learning_rate=0.000001), loss=wbce, metrics=['accuracy']\n",
    "#)\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.Adam(learning_rate=0.0001), loss=\"binary_crossentropy\"\n",
    ")\n",
    "\n",
    "#model.fit(X_train, y_train, validation_data=(val_data,val_target), epochs= epochs, callbacks=[metrics])\n",
    "\n",
    "model.fit(X_train, y_train, epochs= epochs, shuffle=True, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bc4ae39-9ca5-431e-ad38-455e23d4acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7962b0ae-5ea4-4b8f-b828-918af298a88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6755345867818683"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25117aac-7a3d-4ae3-9cd8-ce2b317dfa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 33],\n",
       "       [17, 55]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test[:,1],1*(y_pred[:,1]>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594c708-1d41-4ebd-a308-c1a63b351c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
